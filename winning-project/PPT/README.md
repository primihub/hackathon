# 隐私保护transformer（Privacy-Preserving Transformer）

## 作品介绍

近年来，transformer神经网络凭借其优秀的设计脱颖而出，被各平台结合应用到自己的模型中，如BERT、ViT和GPT等。为了得到相应服务，用户与平台的交互会导致两方隐私的泄露，本作品针对不同的安全性需求，分别基于同态加密和安全多方计算设计并实现了两种transformer安全两方推理方案。

## 作品内容

1）基于同态加密的transformer安全两方推理：针对客户端与服务端的计算资源差异，通过合理分配密文计算任务，保证了客户端数据的隐私性；

2）基于安全多方计算的transformer安全两方推理：设计了适合transformer结构的不经意传输协议和层标准化协议，并通过将原语计算放置离线进行，实现了同时保护两方隐私数据的高效在线推理。

## 作品功能

1）基于同态加密的transformer安全两方推理：在保证服务端不获取任何客户端隐私的前提下，为客户端提供等效服务；

2）基于安全多方计算的transformer安全两方推理：在同时满足服务端模型参数和客户端隐私数据的安全需求的前提下，为客户端提供高效在线服务。

## 应用前景

本作品提出的transformer安全两方推理方案，有助于解决大数据时代下基于transformer神经网络的各种应用的隐私保护问题，相比于目前大多数针对DNN、CNN网络的隐私保护方案，能够进一步拓宽智慧医疗、舆情监测、内容推荐和电子政务等多个领域中隐私保护深度学习的覆盖面。以内容推荐算法为例，人们在使用视频、阅读或购物等平台时，采用transformer安全两方推理，既能获得更为精准的推荐，又不泄露搜索记录。

## 依赖和运行

```
OpenCheetah
libtorch
gcc/g++
cmake
```

主程序分别为`het.cpp`和`mpct.py`。

